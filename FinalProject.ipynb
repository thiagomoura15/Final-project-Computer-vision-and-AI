{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Install Required Packages"
      ],
      "metadata": {
        "id": "kzD2e25Uy86p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IW6oJpdcRkF_"
      },
      "outputs": [],
      "source": [
        "!pip install tf-keras==2.19 --quiet\n",
        "!pip install tensorflow==2.19 --quiet\n",
        "!pip install keras==3.5 --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download and Extract Dataset"
      ],
      "metadata": {
        "id": "KfJ3BfG5y_4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Install gdown, a lightweight tool that allows direct downloads from Google Drive.\n",
        "!pip install gdown\n",
        "\n",
        "# Download the dataset ZIP file from Google Drive using its file ID.\n",
        "# The -O specifies the output filename to save locally.\n",
        "!gdown --id 14BIX16B7tnTgQtanvQRViG_rRVcB0HJB -O rps_dataset.zip\n",
        "\n",
        "# Unzip the downloaded dataset quitely\n",
        "# The contents are extracted into a folder named 'rps_dataset'.\n",
        "!unzip -q rps_dataset.zip -d rps_dataset\n",
        "\n",
        "# Verify that the dataset folder now exists in the Colab environment.\n",
        "print(\"Unzipped folder exists:\", os.path.exists(\"rps_dataset\"))\n",
        "\n",
        "# List the contents of the extracted dataset folder.\n",
        "print(\"Contents:\", os.listdir(\"rps_dataset\") if os.path.exists(\"rps_dataset\") else \"Folder not found\")"
      ],
      "metadata": {
        "id": "kcN8eBDFRp6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Directory Paths\n"
      ],
      "metadata": {
        "id": "OxEhJZ3UzDf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAINING DIRECTORIES\n",
        "train_rock_dir = \"rps_dataset/rps/rps/rock\"\n",
        "train_paper_dir = \"rps_dataset/rps/rps/paper\"\n",
        "train_scissors_dir = \"rps_dataset/rps/rps/scissors\"\n",
        "\n",
        "# VALIDATION DIRECTORIES\n",
        "validation_rock_dir = \"rps_dataset/rps-test-set/rps-test-set/rock\"\n",
        "validation_paper_dir = \"rps_dataset/rps-test-set/rps-test-set/paper\"\n",
        "validation_scissors_dir = \"rps_dataset/rps-test-set/rps-test-set/scissors\"\n",
        "\n",
        "# TEST DIRECTORIES\n",
        "testing_dir = \"rps_dataset/rps-validation\""
      ],
      "metadata": {
        "id": "j23z2CNTUyzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convolutional Neural Network Model"
      ],
      "metadata": {
        "id": "dF0g9mFxzZw_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    #input shape - desired size of the image 150x150 with 3 bytes color\n",
        "    #This is the first convolution\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    # The second convolution\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The third convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The fourth convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The fifth convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # Flatten the results to feed into a DNN\n",
        "    tf.keras.layers.Flatten(),\n",
        "    # 512 neuron hidden layer\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    # incase it is 0, it will apply 3 to ensure something is returned\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "Bo67lrtCj7Ny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display the Model Architecture"
      ],
      "metadata": {
        "id": "Mbx55RqUzqIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display a detailed summary of the model architecture.\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "IR4nmL6hkQvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Custom Metrics and Compile the Model"
      ],
      "metadata": {
        "id": "Jv3DA6XWzpko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# Define metrics\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Custom metric: Recall\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    return true_positives / (possible_positives + K.epsilon())\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Custom metric: Precision\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    return true_positives / (predicted_positives + K.epsilon())\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Compile the model\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(learning_rate=0.001),\n",
        "              metrics=['accuracy',precision_m, recall_m])\n"
      ],
      "metadata": {
        "id": "HROebSmOkXjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preprocessing"
      ],
      "metadata": {
        "id": "YouSHDuWz3cx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# All images will be rescaled by 1./255\n",
        "train_datagen = ImageDataGenerator(rescale=1/255)\n",
        "validation_datagen = ImageDataGenerator(rescale=1/255)\n",
        "testing_datagen = ImageDataGenerator(rescale=1/255)\n",
        "\n",
        "# TRAINING DATA\n",
        "# Flow training images in batches of 128 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        'rps_dataset/rps/rps/',\n",
        "        target_size=(150, 150), #resize image 150 x 150\n",
        "        batch_size=128,\n",
        "        class_mode='categorical') # Since you use categorical_crossentropy loss, you need categorical labels\n",
        "\n",
        "# VALIDATION DATA\n",
        "# Flow validation images in batches of 128 using validation_datagen generator\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        'rps_dataset/rps-test-set/rps-test-set/' ,\n",
        "        target_size=(150, 150), #resize image 150 x 150\n",
        "        batch_size=32,\n",
        "        class_mode='categorical') # Since you use categorical_crossentropy loss, you need categorical labels\n",
        "\n",
        "# TESTING DATA\n",
        "# Flow testing images in batches of 128 using validation_datagen generator\n",
        "testing_generator = testing_datagen.flow_from_directory(\n",
        "        'rps_dataset/rps-validation/',\n",
        "        target_size=(150, 150), #resize image 150 x 150\n",
        "        batch_size=30,\n",
        "        class_mode='categorical') # Since you use categorical_crossentropy loss, you need categorical labels\n"
      ],
      "metadata": {
        "id": "F37mGB05kb_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Custom Callback for Early Stopping"
      ],
      "metadata": {
        "id": "dnusd2TT0HCf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "\n",
        "    # Stops the training when the validation loss falls below 0.4\n",
        "    # Check the loss\n",
        "    if(logs.get('val_loss') < 0.4):\n",
        "\n",
        "      # Stop if threshold is met\n",
        "      print(\"\\nVal Loss is lower than 0.4 so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "# Instantiate class\n",
        "callbacks = myCallback()"
      ],
      "metadata": {
        "id": "Hb8SdrMjyGWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model"
      ],
      "metadata": {
        "id": "lU1s4QrN0N-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=8,\n",
        "      epochs=15,\n",
        "      verbose=1,\n",
        "      validation_data = validation_generator,\n",
        "      validation_steps=8,\n",
        "      callbacks=[callbacks])"
      ],
      "metadata": {
        "id": "N4ILL3QblTqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Whether AI classifies Image into Rock, Paper or Scissors"
      ],
      "metadata": {
        "id": "thHZbIBu0aXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Step 1: Upload an image\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "    # Step 2: Load and display the image\n",
        "    img_path = fn\n",
        "    img = image.load_img(img_path, target_size=(150, 150))\n",
        "    plt.imshow(img)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "    # Step 3: Preprocess\n",
        "    img_array = image.img_to_array(img) / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    # Step 4: Predict\n",
        "    prediction = model.predict(img_array)\n",
        "\n",
        "    # Step 5: Map prediction to class name\n",
        "    class_labels = {v: k for k, v in train_generator.class_indices.items()}\n",
        "    predicted_class = class_labels[np.argmax(prediction)]\n",
        "    confidence = np.max(prediction)\n",
        "\n",
        "    print(f\"Prediction: {predicted_class} (confidence: {confidence:.2f})\")\n",
        "\n"
      ],
      "metadata": {
        "id": "OT0Drsif44Vs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}